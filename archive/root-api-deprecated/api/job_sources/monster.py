"""
Monster job source implementation via web scraping.
"""

from datetime import datetime
from typing import List, Optional

import requests
from bs4 import BeautifulSoup

from .base import JobPosting, JobSource


class MonsterSource(JobSource):
    """Monster job board integration via web scraping."""

    def __init__(self, api_key: str = None, rate_limit: int = 100):
        super().__init__("monster", api_key, rate_limit)
        self.base_url = "https://www.monster.com/jobs/search"

    def search_jobs(self, query: str, location: str = None, limit: int = 10) -> List[JobPosting]:
        """Search Monster jobs via web scraping."""
        if not self._check_rate_limit():
            return []

        try:
            params = {"q": query, "where": location or "", "page": 1}

            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
            }

            response = requests.get(self.base_url, params=params, headers=headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")
            job_cards = soup.find_all("div", class_="job-card", limit=limit)

            jobs = []
            for card in job_cards:
                try:
                    title_elem = card.find("h2", class_="job-title")
                    company_elem = card.find("span", class_="company-name")
                    location_elem = card.find("span", class_="location")
                    link_elem = card.find("a", class_="job-link")

                    if not (title_elem and company_elem and link_elem):
                        continue

                    job_url = link_elem.get("href", "")
                    if not job_url.startswith("http"):
                        job_url = f"https://www.monster.com{job_url}"

                    job_id = (
                        job_url.split("/")[-1].split("?")[0]
                        if job_url
                        else str(hash(title_elem.text))
                    )

                    job = {
                        "id": f"monster_{job_id}",
                        "title": title_elem.text.strip(),
                        "company": company_elem.text.strip(),
                        "location": (
                            location_elem.text.strip() if location_elem else "See description"
                        ),
                        "description": f"Monster job: {title_elem.text.strip()}",
                        "url": job_url,
                        "posted_date": datetime.now(),
                        "remote": "remote" in (location_elem.text.lower() if location_elem else ""),
                        "skills": [],
                        "experience_level": "mid",
                    }

                    jobs.append(self._normalize_job_data(job))

                except Exception:
                    continue

            return jobs

        except requests.RequestException as e:
            print(f"Error fetching Monster jobs: {e}")
            return []
        except Exception as e:
            print(f"Error parsing Monster jobs: {e}")
            return []

    def get_job_details(self, job_id: str) -> Optional[JobPosting]:
        """Get detailed job information from Monster."""
        # Job details endpoint not implemented - users should click through to source URL
        return None
